{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/dataset_cleaned.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1282"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prcp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cantidad_Parque_Vehicular\n",
       "621291     1728\n",
       "419442     1503\n",
       "569102     1500\n",
       "449918     1441\n",
       "487157     1368\n",
       "           ... \n",
       "2695457       1\n",
       "21213         1\n",
       "2573494       1\n",
       "17018         1\n",
       "3063704       1\n",
       "Name: count, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cantidad_Parque_Vehicular.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby_columns = ['Fe_Ocurrencia','De_Causa_Siniestro', 'Cd_Sexo', 'Relacion_Reclamante', 'In_Lista_Negra',\n",
    "#                    'Marca', 'Modelo', 'Año', 'Clase',\n",
    "#                    'Tipo_Dia', 'dia_feriado', 'latitude', #'Cantidad_Parque_Vehicular', \n",
    "#                    'longitude', 'PROVINCIA', 'Clima_Clear', 'Clima_Cloudy', 'Clima_Fair',\n",
    "#                    'Clima_Fog', 'Clima_Rain', 'Clima_Thunderstorm', 'tavg', 'prcp', 'wdir',\n",
    "#                    'wspd', 'pres', 'month_sin', 'month_cos', 'day_sin', 'day_cos']\n",
    "\n",
    "# # Get the frequency of occurrences for each group\n",
    "# frequency_data = df.groupby(groupby_columns).size().reset_index(name='frequency')\n",
    "# frequency_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             float64\n",
       "latitude              float64\n",
       "tavg                  float64\n",
       "dia_feriado             int64\n",
       "Clima_Fog               int64\n",
       "Clima_Thunderstorm      int64\n",
       "pres                  float64\n",
       "prcp                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['longitude','latitude','tavg','dia_feriado','Clima_Fog','Clima_Thunderstorm','pres','prcp']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group in a weekly format\n",
    "groupby_columns = ['PROVINCIA','ano','month','week','De_Causa_Siniestro',\n",
    "                   'Marca', 'Modelo', 'Año', 'Clase']\n",
    "\n",
    "def mode(x):\n",
    "    '''Get the mode of the specified column.'''\n",
    "    return stats.mode(x)[0]\n",
    "\n",
    "tranformations = {  'latitude':'median',\n",
    "                    'longitude':'median',\n",
    "                    'tavg':'median',\n",
    "                    'prcp':'median',\n",
    "                    'wdir':'median',\n",
    "                    'wspd':'median',\n",
    "                    'pres':'median',\n",
    "                    'dia_feriado':mode,\n",
    "                    'Clima_Clear':mode,\n",
    "                    'Clima_Cloudy':mode,\n",
    "                    'Clima_Fair':mode,\n",
    "                    'Clima_Fog':mode,\n",
    "                    'Clima_Rain':mode,\n",
    "                    'Clima_Thunderstorm':mode\n",
    "}\n",
    "\n",
    "# Get the frequency of occurrences for each group\n",
    "frequency_data = df.groupby(groupby_columns).agg(tranformations).reset_index()\n",
    "frequency_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "\n",
    "frequency_data = encode(frequency_data, 'month', 12)\n",
    "frequency_data = encode(frequency_data, 'week', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "De_Causa_Siniestro\n",
       "Accidente/Choque                            7083\n",
       "Rotura de Vidrios y/o Parabrisas            2235\n",
       "Responsabilidad Civil Personas o Cosas      1708\n",
       "Robo o Hurto Accesorios/ Partes o Piezas     329\n",
       "No Registrado                                196\n",
       "Daños Maliciosos al Vehículo/APOV             95\n",
       "Hechos de la Naturaleza                       50\n",
       "Robo o Hurto  Vehiculo                        21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_data.De_Causa_Siniestro.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "De_Causa_Siniestro     object\n",
       "Tipo_Dia               object\n",
       "dia_feriado             int64\n",
       "PROVINCIA              object\n",
       "Clima_Clear             int64\n",
       "Clima_Cloudy            int64\n",
       "Clima_Fair              int64\n",
       "Clima_Fog               int64\n",
       "Clima_Rain              int64\n",
       "Clima_Thunderstorm      int64\n",
       "tavg                  float64\n",
       "prcp                   object\n",
       "wdir                  float64\n",
       "wspd                  float64\n",
       "pres                  float64\n",
       "month_sin             float64\n",
       "month_cos             float64\n",
       "day_sin               float64\n",
       "day_cos               float64\n",
       "ano                     int64\n",
       "month                   int64\n",
       "day                     int64\n",
       "frequency               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder for categorical variables and test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "x = scaler.transform(X)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8201, 319)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X = frequency_data.drop('frequency', axis=1)\n",
    "y = frequency_data['frequency']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n",
    "\n",
    "# Define the numerical and categorical columns\n",
    "num_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define the numerical and categorical transformers\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == object:\n",
    "        X_train[col] = X_train[col].astype(str)\n",
    "\n",
    "mixed_type_columns = [col for col in X_train.columns if len(X_train[col].apply(type).value_counts()) > 1]\n",
    "col_transformer = make_column_transformer(\n",
    "    (num_transformer, num_columns),\n",
    "    (cat_transformer, cat_columns),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_processed = col_transformer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_processed = col_transformer.transform(X_test)\n",
    "\n",
    "print(X_train_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De_Causa_Siniestro     object\n",
      "Tipo_Dia               object\n",
      "dia_feriado             int64\n",
      "PROVINCIA              object\n",
      "Clima_Clear             int64\n",
      "Clima_Cloudy            int64\n",
      "Clima_Fair              int64\n",
      "Clima_Fog               int64\n",
      "Clima_Rain              int64\n",
      "Clima_Thunderstorm      int64\n",
      "tavg                  float64\n",
      "prcp                   object\n",
      "wdir                  float64\n",
      "wspd                  float64\n",
      "pres                  float64\n",
      "month_sin             float64\n",
      "month_cos             float64\n",
      "day_sin               float64\n",
      "day_cos               float64\n",
      "ano                     int64\n",
      "month                   int64\n",
      "day                     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de modelos de regresión\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('Lasso', Lasso()))\n",
    "models.append(('ElasticNet', ElasticNet()))\n",
    "models.append(('SVR', SVR()))\n",
    "models.append(('DecisionTree', DecisionTreeRegressor()))\n",
    "models.append(('ExtraTrees', ExtraTreesRegressor()))\n",
    "models.append(('AdaBoost', AdaBoostRegressor()))\n",
    "models.append(('Bagging', BaggingRegressor()))\n",
    "models.append(('BayesianRidge', BayesianRidge()))\n",
    "models.append(('GradientBoosting', GradientBoostingRegressor()))\n",
    "models.append(('RandomForest', RandomForestRegressor()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('XGBoost', XGBRegressor()))\n",
    "models.append(('LightGBM', LGBMRegressor()))\n",
    "models.append(('CatBoost', CatBoostRegressor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 678, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Daños Maliciosos al Vehículo/APOV'\n\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 678, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Responsabilidad Civil Personas o Cosas'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m nombre, model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m      8\u001b[0m     kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m     cv_resultados \u001b[39m=\u001b[39m cross_val_score(model, X_train, y_train, cv\u001b[39m=\u001b[39;49mkfold, scoring\u001b[39m=\u001b[39;49mscoring)\n\u001b[0;32m     10\u001b[0m     resultados\u001b[39m.\u001b[39mappend(cv_resultados)\n\u001b[0;32m     11\u001b[0m     nombres\u001b[39m.\u001b[39mappend(nombre)\n",
      "File \u001b[1;32mc:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[1;32m--> 328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 678, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Daños Maliciosos al Vehículo/APOV'\n\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 678, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"c:\\Users\\Aneur\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1998, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Responsabilidad Civil Personas o Cosas'\n"
     ]
    }
   ],
   "source": [
    "# Guardamos los resultados del modelo\n",
    "resultados = []\n",
    "nombres = []\n",
    "scoring = 'neg_root_mean_squared_error'\n",
    "# como métrica de puntuación en Scikit-learn, estás expresando tu deseo de maximizar el valor negativo del MSE, lo que equivale a minimizar el MSE real.\n",
    "\n",
    "for nombre, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=None)\n",
    "    cv_resultados = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    resultados.append(cv_resultados)\n",
    "    nombres.append(nombre)\n",
    "    msg = ('{}: {} ({})'.format(nombre, cv_resultados.mean(), cv_resultados.std()))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fe_Ocurrencia         datetime64[ns]\n",
      "De_Causa_Siniestro           float64\n",
      "Tipo_Dia                     float64\n",
      "dia_feriado                  float64\n",
      "PROVINCIA                    float64\n",
      "Clima_Clear                  float64\n",
      "Clima_Cloudy                 float64\n",
      "Clima_Fair                   float64\n",
      "Clima_Fog                    float64\n",
      "Clima_Rain                   float64\n",
      "Clima_Thunderstorm           float64\n",
      "tavg                         float64\n",
      "prcp                         float64\n",
      "wdir                         float64\n",
      "wspd                         float64\n",
      "pres                         float64\n",
      "month_sin                    float64\n",
      "month_cos                    float64\n",
      "day_sin                      float64\n",
      "day_cos                      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Graficamos para tener mejor ilustracion\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparación de algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(resultados)\n",
    "ax.set_xticklabels(nombres)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lime, Shap values, impulso-respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
