{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de Entrenamiento y Prueba de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X = df_final.drop('Frecuencia', axis=1)\n",
    "y = df_final['Frecuencia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Lista de modelos de regresión\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('AdaBoost', AdaBoostRegressor()))\n",
    "models.append(('Bagging', BaggingRegressor()))\n",
    "models.append(('BayesianRidge', BayesianRidge()))\n",
    "models.append(('GradientBoosting', GradientBoostingRegressor()))\n",
    "models.append(('RandomForest', RandomForestRegressor()))\n",
    "models.append(('KNN', KNeighborsRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos los resultados del modelo\n",
    "resultados = []\n",
    "nombres = []\n",
    "scoring = 'neg_mean_squared_error'\n",
    "# como métrica de puntuación en Scikit-learn, estás expresando tu deseo de maximizar el valor negativo del MSE, lo que equivale a minimizar el MSE real.\n",
    "\n",
    "for nombre, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=None)\n",
    "    cv_resultados = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    resultados.append(cv_resultados)\n",
    "    nombres.append(nombre)\n",
    "    msg = ('{}: {} ({})'.format(nombre, cv_resultados.mean(), cv_resultados.std()))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#  Graficamos para tener mejor ilustracion\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparación de algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(resultados)\n",
    "ax.set_xticklabels(nombres)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
